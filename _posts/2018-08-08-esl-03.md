---
layout: post
title: Trevor Hastie，統計的学習の基礎：3章，回帰のための線形手法
updated: 2018-08-08
cover:  "/assets/2018-07-20-lake.jpg"
published: false
categories:
 - machine learning
 - statistics
 - books
---

夏休みは終わってしまったが，引き続き[Trevor Hastie，統計的学習の基礎 ―データマイニング・推論・予測―](http://amzn.asia/ay0yxvo)を勉強している．以下は，**第3章：回帰のための線形手法** のメモ．

# 線形回帰モデルと最小二乗法

- 訓練データが母集団からランダムかつ独立に抽出された場合は，残差平方和は妥当な評価基準．
- ハット行列：$$\mathbf{H} = \mathbf{X}(\mathbf{X}^T \mathbf{X})^{-1} \mathbf{X}^T$$．
  + $$\mathbf{X}$$は1列目に$$1$$を入れた行ベクトルを縦に$$N$$個ならべた入力行列．
  + ハット行列は，出力列ベクトル$$\mathbf{y}$$を$$\mathbf{X}$$の列空間（$$N$$次元）に射影し，推定値$$\hat{\mathbf{y}}$$を得る．
  + $$\mathbf{H}$$がフルランクでない，つまり列ベクトルが線形独立でない場合，最小二乗法では一意に最適なパラメータを推定できなくなる．
